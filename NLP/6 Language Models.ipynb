{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NmJ45sd4DfJ"
      },
      "source": [
        "### Updating and checking the NLTK version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdqpY99J4DfV",
        "outputId": "b252a343-ae41-48c1-b223-7cf8ed566a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-23.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (0.3.6)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U pip\n",
        "!pip install -U dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb4LRyLT4DfY",
        "outputId": "a9c301f1-27ec-4abd-d524-022955ded87e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.9.1\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "print(nltk.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUNHLNx14Dfa"
      },
      "source": [
        "# N-gram using NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFGS4Zqj4Dfc"
      },
      "source": [
        "Traditionally, we can use n-grams to generate language models to predict which word comes next given a history of words.\n",
        "\n",
        "We'll use the lm module in nltk to get a sense of how non-neural language modelling is done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iyJPpMnL4Dfe"
      },
      "outputs": [],
      "source": [
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.util import pad_sequence\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "# from nltk.lm.preprocessing import flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx6Ugq5H4Dfg"
      },
      "source": [
        "If we want to train a bigram model, we need to turn this text into bigrams. Here's what the first sentence of our text would look like if we use the ngrams function from NLTK for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIxp6PEc4Dfh",
        "outputId": "4e9efb74-070b-4b1e-f864-90650a23ee11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\laric\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['i', 'am', 'learning', 'text', 'analytics']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "text = \"I am learning Text Analytics\"\n",
        "tokens = nltk.tokenize.word_tokenize(text.lower())\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jvjrMxgJmGq",
        "outputId": "f5de362c-917e-4a20-c8e5-26c14c87a6ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('i', 'am'), ('am', 'learning'), ('learning', 'text'), ('text', 'analytics')]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(bigrams(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnPitK4x4Dfj",
        "outputId": "f486a882-0243-4e2d-c425-2b6315415edf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('i', 'am', 'learning'),\n",
              " ('am', 'learning', 'text'),\n",
              " ('learning', 'text', 'analytics')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(ngrams(tokens, n=3)) # n = no of grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWdRUdqDKjJ9",
        "outputId": "18f17a3d-4ad1-4ac4-b3c8-64340bb14bb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('i',),\n",
              " ('i', 'am'),\n",
              " ('i', 'am', 'learning'),\n",
              " ('am',),\n",
              " ('am', 'learning'),\n",
              " ('am', 'learning', 'text'),\n",
              " ('learning',),\n",
              " ('learning', 'text'),\n",
              " ('learning', 'text', 'analytics'),\n",
              " ('text',),\n",
              " ('text', 'analytics'),\n",
              " ('analytics',)]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(everygrams(tokens, max_len=3)) # max_len will set the no of maximum grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ3WIBre4Dfl"
      },
      "source": [
        "Add special \"padding\" symbols to the sentence before splitting it into ngrams. Fortunately, NLTK also has a function for that, let's see what it does to the first sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05nYk84e4Dfn",
        "outputId": "45c6ed76-cf69-4f75-9cd3-4f06f2e0c6cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<s>', 'i', 'am', 'learning', 'text', 'analytics', '</s>']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import pad_sequence\n",
        "list(pad_sequence(tokens, pad_left=True, left_pad_symbol=\"<s>\", pad_right=True, right_pad_symbol=\"</s>\", n=2)) \n",
        "# The n order of n-grams, if it's 2-grams, you pad once, 3-grams pad twice, etc. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JycGLGo44Dfp",
        "outputId": "b14c2bd5-1da0-449c-eec7-a09517be4417"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('<s>', 'i'),\n",
              " ('i', 'am'),\n",
              " ('am', 'learning'),\n",
              " ('learning', 'text'),\n",
              " ('text', 'analytics'),\n",
              " ('analytics', '</s>')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_sent = list(pad_sequence(tokens, pad_left=True, left_pad_symbol=\"<s>\", pad_right=True, right_pad_symbol=\"</s>\", n=2))\n",
        "list(ngrams(padded_sent, n=2)) # bigram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFjCk4wr4Dfq"
      },
      "source": [
        "Note the n argument, that tells the function we need padding for bigrams.\n",
        "\n",
        "Now, passing all these parameters every time is tedious and in most cases they can be safely assumed as defaults anyway.\n",
        "\n",
        "Thus the nltk.lm module provides a convenience function that has all these arguments already set while the other arguments remain the same as for pad_sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW1zDLJC4Dfs",
        "outputId": "ef0d63bd-3e72-4b7d-9d2b-ed80747a0fb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<s>', '<s>', 'i', 'am', 'learning', 'text', 'analytics', '</s>', '</s>']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "list(pad_both_ends(tokens, n=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHeRcmqT4Dfv"
      },
      "source": [
        "Combining the two parts discussed so far we get the following preparation steps for one sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoSVN5Pr4Dfw",
        "outputId": "9a8df4f5-5031-40c7-ed0d-ee20e282bbf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('<s>', 'i'),\n",
              " ('i', 'am'),\n",
              " ('am', 'learning'),\n",
              " ('learning', 'text'),\n",
              " ('text', 'analytics'),\n",
              " ('analytics', '</s>')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(bigrams(pad_both_ends(tokens, n=2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaaxtRWA4Dfx"
      },
      "source": [
        "To make our model more robust we could also train it on unigrams (single words) as well as bigrams, its main source of information. NLTK once again helpfully provides a function called everygrams.\n",
        "\n",
        "While not the most efficient, it is conceptually simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td3s76lE4Dfz",
        "outputId": "a4d4bbad-4780-4c5c-dfd2-c851db0f8c4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('<s>',),\n",
              " ('i',),\n",
              " ('am',),\n",
              " ('learning',),\n",
              " ('text',),\n",
              " ('analytics',),\n",
              " ('</s>',)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import everygrams\n",
        "padded_bigrams = list(pad_both_ends(tokens, n=2))\n",
        "list(everygrams(padded_bigrams, max_len=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v55Up9lQ4Df0",
        "outputId": "c9044cad-b000-496e-9259-90fc7d20c647"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('<s>',),\n",
              " ('<s>', 'i'),\n",
              " ('i',),\n",
              " ('i', 'am'),\n",
              " ('am',),\n",
              " ('am', 'learning'),\n",
              " ('learning',),\n",
              " ('learning', 'text'),\n",
              " ('text',),\n",
              " ('text', 'analytics'),\n",
              " ('analytics',),\n",
              " ('analytics', '</s>'),\n",
              " ('</s>',)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(everygrams(padded_bigrams, max_len=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIjJOL0_4Df0"
      },
      "source": [
        "During training and evaluation our model will rely on a vocabulary that defines which words are \"known\" to the model.\n",
        "\n",
        "To create this vocabulary we need to pad our sentences (just like for counting ngrams) and then combine the sentences into one flat stream of words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUIJsAmK4Df1"
      },
      "source": [
        "### Calculating probability of n-grams in a text / sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ispXT0vT4Df2",
        "outputId": "d8c9c807-2999-4e84-dec6-55f0a78694ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['i', 'am', 'learning', 'text', 'analytics']]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\laric\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "text = \"I am learning Text Analytics\"\n",
        "# Tokenize the text.\n",
        "tokenized_text = [list(map(str.lower, nltk.tokenize.word_tokenize(text)))]\n",
        "print(tokenized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aZUKOrmN4Df2"
      },
      "outputs": [],
      "source": [
        "# Preprocess the tokenized text for 3-grams language modelling\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE # Maximum Likelihood Estimation\n",
        "\n",
        "n = 3\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
        "\n",
        "model = MLE(n) # Lets train a 3-grams maximum likelihood estimation model.\n",
        "model.fit(train_data, padded_sents) # model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WJHSaXLZVLF",
        "outputId": "0d25048d-a861-4b55-a72e-a0f672bba0f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<nltk.lm.models.MLE at 0x1d18f630320>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnYdiei54Df3"
      },
      "source": [
        "To get the counts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz1mkPaV4Df4",
        "outputId": "9ef31fa0-c970-476d-c0ba-b5190d77d9da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.counts['i'] # i.e. Count('i')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfarQJmg4Df5",
        "outputId": "665ce7f8-426a-4d9b-a66d-9678185d1c72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.counts[['i']]['am'] # i.e. Count('am'|'i')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G-SbSr14Df5",
        "outputId": "9735acd6-c116-4934-8771-a939d0265722"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.counts[['i', 'am']]['learning'] # i.e. Count('learning'|'i am')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhoVGb9JM6_2"
      },
      "source": [
        "To get the Probablity Values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldmdNkRT4Df6",
        "outputId": "5e7cd807-88a8-4d15-85fc-15b94b88a37f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score('am', 'i'.split())  # P('am'|'i') = C(i am)/C(i) = 1/1 = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpMri5EG4Df6",
        "outputId": "e892212e-ab7c-4c7c-a282-7b31b30414bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score('learning', 'i am'.split())  # P('learning'|'i am')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHSROvTgc6QR",
        "outputId": "00a9fc4f-7814-4cec-9c70-010442cb60aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfdsJfj8br9g",
        "outputId": "d3bf0fab-1b0c-4994-d8b5-a4e4efc4e570"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1111111111111111"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(\"i\") # p(i) = c(i)/c(w)\n",
        "# tokens = 5 & pads = 4 ==> total = 9\n",
        "# c(i) = 1 & c(w) = 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNVz-kmRQzZb",
        "outputId": "74f0efc5-4cc6-4bef-c00a-9df01db56677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('i', 'am', 'learning', 'text', 'analytics'),)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.vocab.lookup(tokenized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPAVz39gQ-is",
        "outputId": "66a8f416-9dc2-4f97-ef3b-99c2692c538b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('i', 'am', '<UNK>'),)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.vocab.lookup([\"i am playing\".split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "901Rt-fpmGe1",
        "outputId": "b0ce27e1-70d3-499b-a6a2-0b7a09c4022b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.counts[['i', 'am']]['playing'] # i.e. Count('playing'|'i am')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Kzed3MRb45"
      },
      "source": [
        "**Laplace Smoothing using NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iLcXV-3bRfY3"
      },
      "outputs": [],
      "source": [
        "from nltk.lm import Laplace\n",
        "\n",
        "n = 3\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
        "\n",
        "model_laplace = Laplace(n) # Lets train a 3-grams maximum likelihood estimation model.\n",
        "model_laplace.fit(train_data, padded_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgjOsJIMSUTk",
        "outputId": "094b9263-ac34-4897-fc25-214c5a0cf004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<nltk.lm.models.Laplace at 0x1d18f631b20>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_laplace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NByJegp_STTF",
        "outputId": "2ee29aa1-e7ad-4564-94f0-814d2d62380b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_laplace.counts[['i']]['am']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fNjiIrLSXbi",
        "outputId": "a06ffd75-8c8e-4aa7-e74c-f838c35d40cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2222222222222222"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_laplace.score('am', 'i'.split())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM7Sdymv4Df7"
      },
      "source": [
        "## N-gram using NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jd3lMAk4Df8",
        "outputId": "741d998a-a591-44b6-d46d-8107b48751a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-gram:  ['A', 'class', 'is', 'a', 'blueprint', 'for', 'the', 'object', '.']\n",
            "2-gram:  ['A class', 'class is', 'is a', 'a blueprint', 'blueprint for', 'for the', 'the object', 'object .']\n",
            "3-gram:  ['A class is', 'class is a', 'is a blueprint', 'a blueprint for', 'blueprint for the', 'for the object', 'the object .']\n",
            "4-gram:  ['A class is a', 'class is a blueprint', 'is a blueprint for', 'a blueprint for the', 'blueprint for the object', 'for the object .']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        " \n",
        "# Function to generate n-grams from sentences.\n",
        "def extract_ngrams(data, num):\n",
        "    n_grams = ngrams(nltk.word_tokenize(data), num)\n",
        "    return [ ' '.join(grams) for grams in n_grams]\n",
        " \n",
        "text = 'A class is a blueprint for the object.'\n",
        " \n",
        "print(\"1-gram: \", extract_ngrams(text, 1))\n",
        "print(\"2-gram: \", extract_ngrams(text, 2))\n",
        "print(\"3-gram: \", extract_ngrams(text, 3))\n",
        "print(\"4-gram: \", extract_ngrams(text, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZzeJq704Df-"
      },
      "source": [
        "## N-gram using TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v660htyc4Df-",
        "outputId": "e900a770-2eb0-49c3-8986-a607dfb25f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-gram:  ['A', 'class', 'is', 'a', 'blueprint', 'for', 'the', 'object']\n",
            "2-gram:  ['A class', 'class is', 'is a', 'a blueprint', 'blueprint for', 'for the', 'the object']\n",
            "3-gram:  ['A class is', 'class is a', 'is a blueprint', 'a blueprint for', 'blueprint for the', 'for the object']\n",
            "4-gram:  ['A class is a', 'class is a blueprint', 'is a blueprint for', 'a blueprint for the', 'blueprint for the object']\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        " \n",
        "# Function to generate n-grams from sentences.\n",
        "def extract_ngrams(data, num):\n",
        "    n_grams = TextBlob(data).ngrams(num)\n",
        "    return [ ' '.join(grams) for grams in n_grams]\n",
        " \n",
        "text = 'A class is a blueprint for the object.'\n",
        " \n",
        "print(\"1-gram: \", extract_ngrams(text, 1))\n",
        "print(\"2-gram: \", extract_ngrams(text, 2))\n",
        "print(\"3-gram: \", extract_ngrams(text, 3))\n",
        "print(\"4-gram: \", extract_ngrams(text, 4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
